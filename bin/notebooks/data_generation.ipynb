{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPCOPPpx3waOllpgEZ9LpcR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kobrue02/evaluating-llm-generated-nlu-data/blob/main/bin/notebooks/data_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the repository and cd into it"
      ],
      "metadata": {
        "id": "mrPxiTtQSIla"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfQQyIA7Qp3d"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/kobrue02/evaluating-llm-generated-nlu-data/\n",
        "%cd evaluating-llm-generated-nlu-data/bin\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary classes and methods"
      ],
      "metadata": {
        "id": "OwC8ge6lSPE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from generate_data import DataGenerationModel, load_prompt\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "WT6cHuCrSprR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Phi-3.5 Model"
      ],
      "metadata": {
        "id": "Vt1xSuS4SYcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phi_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "phi_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
      ],
      "metadata": {
        "id": "KuNipVilT0Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate data using the model"
      ],
      "metadata": {
        "id": "GTik3W8TSc1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phi = DataGenerationModel(model=phi_model, tokenizer=phi_tokenizer)\n",
        "prompt = load_prompt(id=\"chat_template_basic\", query=\"ac_on\", num_samples=5)\n",
        "phi_data = phi.generate_synthetic_data(prompt=prompt)\n",
        "phi_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrHfdt2IUbH9",
        "outputId": "c04264d3-b6ce-4995-fab1-7aacf76e922f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataSet(data=[['Turn on the AC in the back of the car.', 'AC on', 'Put on the air con', 'Can you turn on AC?', 'Please activate the air conditioning system in the vehicle.']], labels=['intent'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}